{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import nltk\n",
    "import spacy\n",
    "from operator import itemgetter\n",
    "import itertools\n",
    "import random\n",
    "import Levenshtein\n",
    "import difflib\n",
    "import pickle\n",
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as output:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "def depickle(file):\n",
    "    file = open(file, 'rb')\n",
    "    data = pickle.load(file)\n",
    "    file.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_between_rules(r, verbose =True):\n",
    "    rule1 = r[0]\n",
    "    rule2 = r[1]\n",
    "    s1 = tag_words(rule1)\n",
    "    s2 = tag_words(rule2)\n",
    "    s = difflib.SequenceMatcher(None, s1, s2)\n",
    "    verbose_list = []\n",
    "    if verbose:\n",
    "        for tag, i1, i2, j1, j2 in s.get_opcodes():\n",
    "            verbose_list.append((tag, s1[i1:i2], s2[j1:j2]))\n",
    "#             print('{:7} {!r:>8} --> {!r}'.format(tag, s1[i1:i2], s2[j1:j2]))\n",
    "    return (verbose_list,s.ratio())\n",
    "\n",
    "def get_score_only(s1,s2,verbose=False):\n",
    "    s = difflib.SequenceMatcher(None, s1, s2)\n",
    "    verbose_list = []\n",
    "    if verbose:\n",
    "        for tag, i1, i2, j1, j2 in s.get_opcodes():\n",
    "            verbose_list.append((tag, s1[i1:i2], s2[j1:j2]))\n",
    "#             print('{:7} {!r:>8} --> {!r}'.format(tag, s1[i1:i2], s2[j1:j2]))\n",
    "    return (s.ratio(),verbose_list)\n",
    "#     d = difflib.Differ()\n",
    "#     result = list(d.compare(s1, s2))\n",
    "#     if verbose:\n",
    "#         from pprint import pprint\n",
    "#         pprint(result)\n",
    "#     return \n",
    "#     s = difflib.SequenceMatcher(None,s1,s2)\n",
    "#     for opcode in s.get_opcodes():\n",
    "#         print(\"%6s\" s1[%d:%d], s2[%d:%d] % opcode)\n",
    "#     print(Levenshtein.distance(s1,s2))\n",
    "#     return Levenshtein.editops(s1,s2)\n",
    "# [('replace', 1, 1), ('replace', 2, 2), ('replace', 3, 3)]\n",
    "\n",
    "#     return s.get_opcodes()\n",
    "\n",
    "def rSubset(arr, r): \n",
    "  \n",
    "    # return list of all subsets of length r \n",
    "    # to deal with duplicate subsets use  \n",
    "    # set(list(combinations(arr, r))) \n",
    "    return list(itertools.combinations(arr, r))\n",
    "\n",
    "def tag_words(s):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    output_dir = 'my_mixed_random/'\n",
    "    nlp2 = spacy.load(output_dir)\n",
    "    ent_list = []\n",
    "    doc2 = nlp2(s)\n",
    "    for ent in doc2.ents:\n",
    "        ent_list.append({'label':ent.label_, 'start':ent.start, 'end':ent.end})\n",
    "    doc = nlp(s)\n",
    "    for token in doc:\n",
    "        ent_list.append({'label':token.pos_, 'start':token.idx, 'end': token.idx+len(token.text)})\n",
    "    ent_list = sorted(ent_list,\n",
    "                          key=lambda k: (k['start']))\n",
    "    sign_list = []\n",
    "    for tag in ent_list:\n",
    "        sign_list.append(tag['label'])\n",
    "    return sign_list\n",
    "# r1= '(i)any person who is or has during the six months prior to the concerned act been associated with a company, directly or indirectly, in any capacity including by'\n",
    "# r2 = 'reason of frequent communication with its officers or by being in any contractual, fiduciary or employment relationship or by being a director, officer or an employee of the company or holds any position including a professional or'\n",
    "# r1 = 'Provided that in case the disclosure is made after twenty four hours of occurrence of the event or information, the listed entity shall, along with such disclosures provide explanation for delay:'\n",
    "# r2 = 'Provided that in case the disclosure is made after twenty four hours of occurrence of the event or information, the listed entity shall, along with such disclosures provide explanation for the delay.'\n",
    "r1 = '43.In order to remove any difficulties in respect of the application or interpretation of these regulations, the Board may issue clarifications or guidelines in the form of circulars.'\n",
    "r2 = '27.In order to remove any difficulties in the interpretation or application of the provisions of these regulations, the Board may issue clarifications or guidelines from time to time.'\n",
    "# print(r1)\n",
    "# print(r2)\n",
    "# similarity_between_rules((r1,r2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rulewise_files = {}\n",
    "list_rules_all =[]\n",
    "file_array = os.listdir('data_rules/data')\n",
    "for file_name in file_array:\n",
    "    if file_name.endswith(\".json\"):\n",
    "        f = open('data_rules/data/'+file_name)\n",
    "        object_json2 = json.load(f)\n",
    "        jj = list({v['id']:v for v in object_json2}.values())\n",
    "        local_rules = []\n",
    "        for rule in jj:\n",
    "            if (not rule['rule'].isupper()) and('Page' not in rule['rule'])and('means' not in rule['rule']) and ('w.e.f.' not in rule['rule']) and ('_' not in rule['rule']) and ('SECURITIES AND EXCHANGE BOARD OF INDIA' not in rule['rule']):\n",
    "                local_rules.append(rule['rule'])\n",
    "                list_rules_all.append((rule['rule'], file_name))\n",
    "        rulewise_files[file_name] = local_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rules = {}\n",
    "for k in list_rules_all:\n",
    "    try:\n",
    "        if (not rule['rule'].isupper()) and('Page' not in rule['rule'])and('means' not in rule['rule']) and ('w.e.f.' not in rule['rule']) and ('_' not in rule['rule']) and ('SECURITIES AND EXCHANGE BOARD OF INDIA' not in rule['rule']) and (len(k[0])<=38) and (k[0][0]!='(') and (k[0][2]!='.')and (k[0][2]!=')')and (k[0][1]!='.'):\n",
    "            pass\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_with_tags = depickle('rule_tags_all_regulations_with_pos.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7405"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rules_with_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_object(order,'similarity.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = dict(list(rules_with_tags.items())[0: 20]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201\n"
     ]
    }
   ],
   "source": [
    "new_rules = {}\n",
    "count = 0\n",
    "remove_list = ['12.(1) The Securities and Exchange Board of India (Prohibition of Insider Trading) Regulations, 1992 are hereby repealed.']\n",
    "for rule in rules_with_tags:\n",
    "    try:\n",
    "        if count>200:\n",
    "            break\n",
    "#     if  ('w.e.f.' in rule):\n",
    "#         k = rule.split('Inserted')\n",
    "#         print(k)\n",
    "        if ('No. LAD-NRO' not in rule)and(not rule.isupper()) and('Page' not in rule)and('means' not in rule) and ('w.e.f.' not in rule) and ('_' not in rule) and ('SECURITIES AND EXCHANGE BOARD OF INDIA' not in rule) and not((len(rule)<=38) and (rule[0]!='(') and (rule[2]!='.')and (rule[2]!=')')and (rule[1]!='.')):\n",
    "    \n",
    "#     if (('Page' not in rule) and ('w.e.f.' not in rule) and('means' not in rule)and(len(rule)>80)and(rule not in remove_list)):\n",
    "                new_rules[rule] = [d for d in rules_with_tags[rule]]\n",
    "#                 new_rules[rule] = [d['label'] for d in rules_with_tags[rule]]\n",
    "                count += 1\n",
    "    except:\n",
    "        pass\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interfile rules' similarity\n",
    "global_similarity= {}\n",
    "# random.shuffle(new_rules)\n",
    "# list_rules_all = list_rules_all[:5]\n",
    "for rule1 in new_rules:\n",
    "    for rule2 in new_rules:\n",
    "        if rule1!= rule2:\n",
    "            if (rule2,rule1) not in global_similarity.keys():\n",
    "                global_similarity[(rule1,rule2)] =get_score_only(new_rules[rule1],new_rules[rule2])\n",
    "# order = sorted(global_similarity.items(), key=itemgetter(1), reverse=True)\n",
    "order = sorted(global_similarity.items(),key=lambda x: x[1][0], reverse=True)\n",
    "# r_order = sorted(global_similarity.items(), key=itemgetter(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# # open a file, where you stored the pickled data\n",
    "# file = open('similarity.pkl', 'rb')\n",
    "# # dump information to that file\n",
    "# order = pickle.load(file)\n",
    "# # close the file\n",
    "# file.close()\n",
    "# data = []\n",
    "# for rule in order:\n",
    "# #     if (rule[0][0]!=rule[0][1]) and (rule[0][0]!=rule[0][1][[:-1]]):\n",
    "#     if (rule[1]<1.0) and (rule[1]>=0.6):\n",
    "#         if ('Inserted' not in rule[0]) and ('Substituted' not in rule[0]) and ('-' not in rule[0]):\n",
    "#             print(rule[0][0])\n",
    "#             print(rule[0][1])\n",
    "#             print(rule[1])\n",
    "#             data.append((rule[0][0], rule[0][1], rule[1]))\n",
    "#     #     print(order[rule])\n",
    "#             print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = []\n",
    "# for rule in order:\n",
    "# #     if (rule[0][0]!=rule[0][1]) and (rule[0][0]!=rule[0][1][[:-1]]):\n",
    "#     if (rule[1]<1.0):\n",
    "#         if ('Inserted' not in rule[0]) and ('Substituted' not in rule[0]) and ('-' not in rule[0]):\n",
    "#             print(rule[0][0])\n",
    "#             print(rule[0][1])\n",
    "#             print(rule[1])\n",
    "#             data.append((rule[0][0],rule[0][1],rule[1]))\n",
    "#     #     print(order[rule])\n",
    "\n",
    "#     print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# csvfile = open('simi.csv','w', newline='')\n",
    "# obj = csv.writer(csvfile)\n",
    "# obj.writerows(data)\n",
    "# obj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Intrafile comparison of similarity of rules.\n",
    "# #Storing intra rule score in a dictionary. and sort by value.\n",
    "# same_file_similarty_ranking = {}\n",
    "# for file in rulewise_files:\n",
    "#     local_similarity = {}\n",
    "#     rad = rSubset(rulewise_files[file], 2)\n",
    "#     for r in rad:\n",
    "# #         print(r[0])\n",
    "# #         print(r[1])\n",
    "# #         print(similarity_between_rules(r))\n",
    "#         local_similarity[r] = similarity_between_rules(r)\n",
    "# #         print('\\n')\n",
    "\n",
    "#     order = sorted(local_similarity.items(), key=itemgetter(1), reverse=True)\n",
    "#     same_file_similarty_ranking[file] = order"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
