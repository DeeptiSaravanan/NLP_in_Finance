{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import json\n",
    "import pickle\n",
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as output:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Person In charge',\n",
       " 'Place',\n",
       " 'Assets',\n",
       " 'Person - General',\n",
       " 'Object',\n",
       " 'Company',\n",
       " 'Penalty',\n",
       " 'Investigation',\n",
       " 'Legal Doc',\n",
       " 'time',\n",
       " 'Action']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('insider_rule_dump.json') as f:\n",
    "    data = json.load(f)\n",
    "with open('project_2_labels.json') as f:\n",
    "    label_file = json.load(f)\n",
    "labels = []\n",
    "for k in label_file:\n",
    "    labels.append(k['text'])\n",
    "labels.append('Action')\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting rules as a dictionary to be given to rule objects.\n",
    "def extract_attributes(line):\n",
    "    output_dir = 'my_mixed_random/'\n",
    "    nlp2 = spacy.load(output_dir)\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(line)\n",
    "    doc2 = nlp2(line)\n",
    "    output_dict = {k:[] for k in labels}\n",
    "    for token in doc:\n",
    "        if token.pos_ == 'VERB':\n",
    "            output_dict['Action'].append(token.text)\n",
    "    for ent in doc2.ents:\n",
    "        output_dict[ent.label_].append(ent.text)\n",
    "    return output_dict\n",
    "#Cleaning objects for repetitions and removing stop words in verbs/actions.\n",
    "def clean_attributes(output_dict):\n",
    "    clean_dir = {}\n",
    "    for k in output_dict.keys():\n",
    "        clean_dir[k]=list(set(output_dict[k]))\n",
    "    try:\n",
    "        clean_dir['Action'].remove('shall')\n",
    "    except ValueError:\n",
    "        pass\n",
    "    try:\n",
    "        clean_dir['Action'].remove('may')\n",
    "    except ValueError:\n",
    "        pass\n",
    "    try:\n",
    "        clean_dir['Action'].remove('would')\n",
    "    except ValueError:\n",
    "        pass\n",
    "    return clean_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Person In charge': [], 'Place': [], 'Assets': [], 'Person - General': ['Any person', 'insider', 'persons'], 'Object': ['unpublished price sensitive information', 'legitimate purpose', 'unpublished price sensitive information'], 'Company': [], 'Penalty': [], 'Investigation': [], 'Legal Doc': ['regulations', 'notice', 'regulations'], 'time': [], 'Action': ['shall', 'considered', 'shall', 'given', 'maintain']}\n",
      "{'Person In charge': [], 'Place': [], 'Assets': [], 'Person - General': ['insider', 'Any person', 'persons'], 'Object': ['legitimate purpose', 'unpublished price sensitive information'], 'Company': [], 'Penalty': [], 'Investigation': [], 'Legal Doc': ['regulations', 'notice'], 'time': [], 'Action': ['given', 'considered', 'maintain']}\n"
     ]
    }
   ],
   "source": [
    "line = data[11]\n",
    "print(extract_attributes(line))\n",
    "print(clean_attributes(extract_attributes(line)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#The following functions are used to index the documents is order and combine them chapter wise.\n",
    "p = re.compile(r'^(\\(\\d\\)|\\(\\d\\d\\))')\n",
    "new_data = []\n",
    "int_list = []\n",
    "for k in range(len(data)):\n",
    "    int_list.append(data[k])\n",
    "    if k+1<len(data):\n",
    "        if not p.findall(data[k+1]):\n",
    "            pass\n",
    "        else:\n",
    "            new_data.append(''.join(map(str, int_list)))\n",
    "            int_list = []\n",
    "\n",
    "for line in new_data:\n",
    "    p = re.compile(r'^(\\(\\d\\)|\\(\\d\\d\\))')\n",
    "\n",
    "reg_data = []\n",
    "chap_list = []\n",
    "for k in range(len(new_data)):\n",
    "    chap_list.append(new_data[k])\n",
    "    if k+1<len(new_data):\n",
    "        if p.findall(new_data[k+1])[0][1]=='1':\n",
    "            reg_data.append(chap_list)\n",
    "            chap_list = []\n",
    "reg_dict = {}\n",
    "#reg_dict is a dictionary of rules with keys as chapter numbers and values as list of ordered rules(strings).\n",
    "count = 0\n",
    "for k in reg_data:\n",
    "    rules_dict = {}\n",
    "    for i in k:\n",
    "        rules_dict[p.findall(i)[0][1]] = i \n",
    "    count +=1\n",
    "    reg_dict[count] = rules_dict\n",
    "\n",
    "# print(reg_dict)\n",
    "\n",
    "raw_reg_dict = reg_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'1': <Rule.Rule at 0x7f6906971400>, '2': <Rule.Rule at 0x7f6902a295b0>},\n",
       " 2: {'1': <Rule.Rule at 0x7f6902beca30>},\n",
       " 3: {'1': <Rule.Rule at 0x7f6902bbcf40>,\n",
       "  '2': <Rule.Rule at 0x7f69051980a0>,\n",
       "  '3': <Rule.Rule at 0x7f6902e98310>,\n",
       "  '4': <Rule.Rule at 0x7f6905316f40>},\n",
       " 4: {'1': <Rule.Rule at 0x7f690532e790>},\n",
       " 5: {'1': <Rule.Rule at 0x7f69027e0580>,\n",
       "  '2': <Rule.Rule at 0x7f690531f160>,\n",
       "  '3': <Rule.Rule at 0x7f6902ee0760>,\n",
       "  '4': <Rule.Rule at 0x7f6902ab1730>},\n",
       " 6: {'1': <Rule.Rule at 0x7f6901ea5430>,\n",
       "  '2': <Rule.Rule at 0x7f69052ff8b0>,\n",
       "  '3': <Rule.Rule at 0x7f69028a4370>,\n",
       "  '4': <Rule.Rule at 0x7f6902b38cd0>},\n",
       " 7: {'1': <Rule.Rule at 0x7f6902a3fb80>, '2': <Rule.Rule at 0x7f690315af70>},\n",
       " 8: {'1': <Rule.Rule at 0x7f6902e8d670>},\n",
       " 9: {'1': <Rule.Rule at 0x7f69027e0d60>, '2': <Rule.Rule at 0x7f6903117a90>},\n",
       " 10: {'1': <Rule.Rule at 0x7f6906a9d8e0>,\n",
       "  '2': <Rule.Rule at 0x7f6902ee5310>,\n",
       "  '3': <Rule.Rule at 0x7f6902bbf070>},\n",
       " 11: {'1': <Rule.Rule at 0x7f6906965b50>,\n",
       "  '2': <Rule.Rule at 0x7f69032800d0>,\n",
       "  '3': <Rule.Rule at 0x7f690ea55790>},\n",
       " 12: {'1': <Rule.Rule at 0x7f6902ad2cd0>,\n",
       "  '2': <Rule.Rule at 0x7f6902e79310>,\n",
       "  '3': <Rule.Rule at 0x7f6902e62f40>},\n",
       " 13: {'1': <Rule.Rule at 0x7f6901f90040>, '2': <Rule.Rule at 0x7f6902af0070>},\n",
       " 14: {'1': <Rule.Rule at 0x7f69051b0b20>,\n",
       "  '2': <Rule.Rule at 0x7f690326eaf0>,\n",
       "  '3': <Rule.Rule at 0x7f69052480a0>,\n",
       "  '4': <Rule.Rule at 0x7f6902d5f400>,\n",
       "  '5': <Rule.Rule at 0x7f6902ab1a00>},\n",
       " 15: {'1': <Rule.Rule at 0x7f69031d4ac0>,\n",
       "  '2': <Rule.Rule at 0x7f6903279490>,\n",
       "  '3': <Rule.Rule at 0x7f6902b380a0>},\n",
       " 16: {'1': <Rule.Rule at 0x7f69027e0b50>, '2': <Rule.Rule at 0x7f69031ecd00>},\n",
       " 17: {'1': <Rule.Rule at 0x7f69051a6ca0>,\n",
       "  '2': <Rule.Rule at 0x7f69050e1dc0>,\n",
       "  '3': <Rule.Rule at 0x7f690328c310>,\n",
       "  '4': <Rule.Rule at 0x7f690532e670>,\n",
       "  '5': <Rule.Rule at 0x7f6902afe3d0>},\n",
       " 18: {'1': <Rule.Rule at 0x7f6901ea5850>, '2': <Rule.Rule at 0x7f6902bcda90>},\n",
       " 19: {'1': <Rule.Rule at 0x7f6901d19040>},\n",
       " 20: {'1': <Rule.Rule at 0x7f69052c25b0>, '2': <Rule.Rule at 0x7f6903210130>},\n",
       " 21: {'1': <Rule.Rule at 0x7f6902beeac0>,\n",
       "  '2': <Rule.Rule at 0x7f6902b3b280>,\n",
       "  '3': <Rule.Rule at 0x7f69022149a0>},\n",
       " 22: {'1': <Rule.Rule at 0x7f690191bc10>,\n",
       "  '2': <Rule.Rule at 0x7f6902bf9340>,\n",
       "  '3': <Rule.Rule at 0x7f69028e8d00>,\n",
       "  '4': <Rule.Rule at 0x7f6902bec610>,\n",
       "  '5': <Rule.Rule at 0x7f6902a29ca0>}}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Rule import Rule\n",
    "regulation_doc = {}\n",
    "for chapter_num in raw_reg_dict:\n",
    "    regulation_doc[chapter_num] = {}\n",
    "    for rule_index in raw_reg_dict[chapter_num]:\n",
    "        d = clean_attributes(extract_attributes(raw_reg_dict[chapter_num][rule_index]))\n",
    "        #In the above line of code, a rule text present in the indexed rules and regulations is\n",
    "        #sent to a ner model and its 11 attributes are collected and sent back in a dictionary.\n",
    "        #This dictionary is sent to the import module of a rule to create and fill a rule object.\n",
    "        r = Rule('Insider Trading', int(chapter_num)+1, int(rule_index)+1, raw_reg_dict[chapter_num][rule_index])\n",
    "        r.fill_attributes(d)\n",
    "        regulation_doc[chapter_num][rule_index] = r\n",
    "regulation_doc        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Regulation.Regulation at 0x7f69031d4820>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Regulation import Regulation\n",
    "insider_regulation_object = Regulation('Insider Trading', regulation_doc) \n",
    "insider_regulation_object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_object(insider_regulation_object, 'insider_trading_regulation_object.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
